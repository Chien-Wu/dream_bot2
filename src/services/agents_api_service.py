# src/services/agents_api_service.py
import json
from dataclasses import dataclass
from typing import Optional

from openai import OpenAI

from config import config
from src.utils import setup_logger
from src.models import AIResponse
from src.services.database_service import DatabaseService

logger = setup_logger(__name__)


class AIValidationError(Exception):
    """Raised when AI response fails required field validation."""
    pass


@dataclass
class ConversationMessage:
    role: str  # 'system', 'user', 'assistant'
    content: str


class AgentsAPIService:
    """
    ä½¿ç”¨ OpenAI Prompt API é€²è¡Œå›è¦†ï¼š
    - responses.create() æ­é… prompt ID
    - è§£æ JSON å›è¦†ä¸¦è¿”å›å®Œæ•´çš„ AIResponse çµæ§‹
    """

    def __init__(self, database_service: DatabaseService, line_service=None):
        self.config = config.openai
        self.line_service = line_service
        self.db = database_service

        # OpenAI å®˜æ–¹ SDK
        self.client = OpenAI(api_key=self.config.api_key)

        self.prompt_id = self.config.prompt_id
        self.prompt_version = self.config.prompt_version

        if not self.prompt_id:
            raise ValueError("OPENAI_PROMPT_ID must be set")

        # Initialize tool functions (needs to be instance for small AI calls)
        from src.services.tool_functions import ToolFunctions
        self.tool_functions = ToolFunctions()

    def get_response(self, user_id: str, user_input: str) -> AIResponse:
        """
        ä½¿ç”¨ OpenAI Prompt API åŸ·è¡Œå–®è¼ªå°è©±ã€‚
        """
        try:
            input_text = user_input

            # å–å¾—ç”¨æˆ¶ä¸Šä¸€è¼ªå›æ‡‰ID
            last_response_id = self.db.get_user_thread_id(user_id)

            # æº–å‚™ prompt åƒæ•¸ï¼ˆå‹•æ…‹æ±ºå®šæ˜¯å¦åŒ…å« versionï¼‰
            prompt_params = {"id": self.prompt_id}
            if self.prompt_version:
                prompt_params["version"] = self.prompt_version
                logger.debug(f"Using prompt version: {self.prompt_version}")
            else:
                logger.debug("Using latest prompt version (auto-update)")

            # æº–å‚™APIå‘¼å«åƒæ•¸
            kwargs = {
                "prompt": prompt_params,
                "input": input_text,
                "truncation": "auto"  # Auto-truncate from beginning if context exceeds limit
            }

            # å¦‚æœæœ‰ä¸Šä¸€è¼ªå°è©±ï¼ŒåŠ å…¥previous_response_id
            if last_response_id:
                kwargs["previous_response_id"] = last_response_id

            # å‘¼å« Responses API
            response = self.client.responses.create(**kwargs)

            # å„²å­˜æ­¤æ¬¡å›æ‡‰IDä¾›ä¸‹æ¬¡å°è©±ä½¿ç”¨
            self.db.set_user_thread_id(user_id, response.id)

            # CHECK FOR FUNCTION CALLS
            function_calls = self._extract_function_calls(response)

            if function_calls:
                logger.info(f"Detected {len(function_calls)} function call(s)")
                # Handle function calls and get final response
                response = self._handle_function_calls(user_id, response, function_calls)
                # Update response ID after function calls
                self.db.set_user_thread_id(user_id, response.id)

            # å–å¾—å›è¦†æ–‡å­—
            if hasattr(response, 'output_text'):
                response_text = response.output_text
            elif hasattr(response, 'content'):
                response_text = response.content
            else:
                response_text = str(response)

            # è§£æ JSON å›è¦†
            parsed = self._parse_json_response(response_text, user_id)

            # è½åº«
            message_history_id = self.db.log_message(
                user_id=user_id,
                content=user_input,
                ai_response=parsed.text,
                ai_explanation=parsed.explanation,
                confidence=parsed.confidence,
            )
            if message_history_id:
                self.db.save_ai_detail(message_history_id, parsed)

            return parsed

        except Exception as e:
            logger.error(f"Error in get_response: {e}")
            # Re-raise all API errors so message processor can handle them as ai_error
            raise e

    # ===== è¼”åŠ© =====
    def _parse_json_response(self, response_text: str, user_id: str) -> AIResponse:
        """Parse JSON response from the agent."""
        try:
            # æ¸…ç†å›è¦†æ–‡å­—ï¼Œç§»é™¤å¯èƒ½çš„å‰å¾Œæ–‡å­—æˆ–Markdown
            response_text = response_text.strip()

            # å°‹æ‰¾ JSON éƒ¨åˆ†
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}')

            if start_idx == -1 or end_idx == -1:
                logger.error(f"No JSON found in response: {response_text[:200]}")
                raise AIValidationError("No JSON found in AI response")

            json_str = response_text[start_idx:end_idx + 1]
            parsed_json = json.loads(json_str)

            # STEP 1: Validate required fields exist
            # Note: 'text' can be empty (intentional silence), but must exist
            if 'text' not in parsed_json:
                raise AIValidationError("Missing 'text' field")

            required_fields = ['explanation', 'confidence']
            missing_fields = [f for f in required_fields if f not in parsed_json]

            if missing_fields:
                error_msg = f"Missing required fields: {missing_fields}"
                logger.error(f"AI validation failed: {error_msg}, response: {response_text[:500]}")
                raise AIValidationError(error_msg)

            # STEP 2: Validate explanation is non-empty
            if not parsed_json['explanation'] or not str(parsed_json['explanation']).strip():
                raise AIValidationError("Explanation field cannot be empty")

            # STEP 3: Validate confidence range
            try:
                confidence = float(parsed_json['confidence'])
                if not (0.0 <= confidence <= 1.0):
                    raise AIValidationError(f"Confidence {confidence} out of range [0.0, 1.0]")
            except (ValueError, TypeError) as e:
                raise AIValidationError(f"Invalid confidence value: {parsed_json['confidence']}")

            # STEP 4: Create AIResponse with validated required fields and optional fields
            return AIResponse(
                text=parsed_json['text'],
                confidence=confidence,
                explanation=parsed_json['explanation'],
                user_id=user_id,
                intent=parsed_json.get("intent"),
                queries=parsed_json.get("queries", []),
                sources=parsed_json.get("sources", []),
                gaps=parsed_json.get("gaps", []),
                policy_scope=parsed_json.get("policy", {}).get("scope"),
                policy_risk=parsed_json.get("policy", {}).get("risk"),
                policy_pii=parsed_json.get("policy", {}).get("pii"),
                policy_escalation=parsed_json.get("policy", {}).get("escalation"),
                notes=parsed_json.get("notes")
            )

        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing error: {e}, response: {response_text[:500]}")
            raise AIValidationError(f"Invalid JSON in AI response: {e}")
        except AIValidationError:
            # Re-raise validation errors
            raise
        except Exception as e:
            logger.error(f"Unexpected error parsing response: {e}")
            raise AIValidationError(f"Failed to parse AI response: {e}")
    
    def _extract_function_calls(self, response) -> list:
        """
        Extract function calls from OpenAI response.

        Args:
            response: OpenAI response object

        Returns:
            List of function call dictionaries with name, arguments, and call_id
        """
        function_calls = []

        try:
            if not hasattr(response, 'output') or not response.output:
                return function_calls

            for output_item in response.output:
                if hasattr(output_item, 'type') and output_item.type == "function_call":
                    function_calls.append({
                        "name": output_item.name,
                        "arguments": output_item.arguments,
                        "call_id": output_item.call_id
                    })
                    logger.info(f"Found function call: {output_item.name} with args: {output_item.arguments}")

        except Exception as e:
            logger.error(f"Error extracting function calls: {e}")

        return function_calls

    def _handle_function_calls(self, user_id: str, initial_response, function_calls: list):
        """
        Execute function calls and send results back to OpenAI.

        Args:
            user_id: User ID for context
            initial_response: Initial response containing function calls
            function_calls: List of function calls to execute

        Returns:
            Final response from OpenAI after function execution
        """
        try:
            # Execute each function and collect results
            function_results = []

            for func_call in function_calls:
                function_name = func_call["name"]
                arguments_str = func_call["arguments"]
                call_id = func_call["call_id"]

                logger.info(f"Executing function: {function_name}")
                logger.info(f"Arguments: {arguments_str}")

                # Execute the function
                result = self._execute_function(function_name, arguments_str)

                logger.info(f"Function result: {result}")

                # If debug mode is enabled, push small AI output to user
                if config.show_ai_debug_info:
                    if function_name == "ask_knowledge_expert":
                        self._push_small_ai_debug_info(user_id, arguments_str, result)
                    elif function_name == "check_submission_status":
                        self._push_submission_ai_debug_info(user_id, arguments_str, result)

                # Prepare result for OpenAI
                function_results.append({
                    "type": "function_call_output",
                    "call_id": call_id,
                    "output": result
                })

            # Send function results back to OpenAI to get final response
            logger.info("Sending function results back to OpenAI...")

            final_response = self.client.responses.create(
                prompt={
                    "id": self.prompt_id,
                    "version": self.prompt_version
                },
                input=function_results,
                previous_response_id=initial_response.id,
                truncation="auto"  # Auto-truncate from beginning if context exceeds limit
            )

            logger.info("Received final response from OpenAI after function execution")

            return final_response

        except Exception as e:
            logger.error(f"Error handling function calls: {e}")
            raise e

    def _execute_function(self, function_name: str, arguments_str: str) -> str:
        """
        Execute a function by name with given arguments.

        Args:
            function_name: Name of the function to execute
            arguments_str: JSON string of arguments

        Returns:
            Function result as string
        """
        try:
            # Import tool functions
            from src.services.tool_functions import ToolFunctions
            import json

            # Parse arguments
            arguments = json.loads(arguments_str)

            # Map function names to actual functions
            function_map = {
                "get_current_time": ToolFunctions.get_current_time,  # Static method
                "ask_knowledge_expert": self.tool_functions.ask_knowledge_expert,  # Instance method (needs OpenAI client)
                "check_submission_status": self.tool_functions.check_submission_status,  # Instance method (needs OpenAI client)
            }

            if function_name not in function_map:
                error_msg = f"Unknown function: {function_name}"
                logger.error(error_msg)
                return error_msg

            # Execute the function
            func = function_map[function_name]
            result = func(**arguments)

            return result

        except json.JSONDecodeError as e:
            error_msg = f"Failed to parse function arguments: {e}"
            logger.error(error_msg)
            return error_msg

        except Exception as e:
            error_msg = f"Error executing function {function_name}: {e}"
            logger.error(error_msg)
            return error_msg

    def _push_small_ai_debug_info(self, user_id: str, arguments_str: str, result: str) -> None:
        """
        Push small AI debug information to LINE user when debug mode is enabled.

        Args:
            user_id: LINE user ID
            arguments_str: JSON string of function arguments
            result: Function result (small AI response)
        """
        try:
            # Skip if line_service not available
            if not self.line_service:
                logger.warning("LineService not available, skipping small AI debug info push")
                return

            import time

            # Parse arguments to get question
            arguments = json.loads(arguments_str)
            question = arguments.get("question", "")
            context = arguments.get("context", "")

            # Parse result to get small AI response
            try:
                result_json = json.loads(result)
                answer = result_json.get("answer", result)
                confidence = result_json.get("confidence", "N/A")
                sources = result_json.get("sources", [])
            except json.JSONDecodeError:
                answer = result
                confidence = "N/A"
                sources = []

            # Build debug message
            debug_msg = "ğŸ¤– å° AI (çŸ¥è­˜å°ˆå®¶) å›è¦†ï¼š\n"
            debug_msg += "â”€" * 30 + "\n"
            debug_msg += f"ğŸ“ å•é¡Œï¼š{question}\n"
            if context:
                debug_msg += f"ğŸ“Œ èƒŒæ™¯ï¼š{context}\n"
            debug_msg += "\nğŸ’¡ å° AI ç­”æ¡ˆï¼š\n"
            debug_msg += f"{answer}\n"
            debug_msg += "\n" + "â”€" * 30 + "\n"
            debug_msg += f"ğŸ¯ ä¿¡å¿ƒåº¦ï¼š{confidence}\n"
            if sources:
                debug_msg += f"ğŸ“š ä¾†æºï¼š{', '.join(sources)}\n"

            # Push message
            time.sleep(0.3)  # Small delay to ensure proper message order
            self.line_service.push_message(user_id, debug_msg)

            logger.info(f"Pushed small AI debug info to user {user_id}")

        except Exception as e:
            logger.error(f"Failed to push small AI debug info: {e}")
            # Don't raise - debug info failure shouldn't break the main flow

    def _push_submission_ai_debug_info(self, user_id: str, arguments_str: str, result: str) -> None:
        """
        Push Submission AI debug information to LINE user when debug mode is enabled.

        Args:
            user_id: LINE user ID
            arguments_str: JSON string of function arguments
            result: Function result (Submission AI response)
        """
        try:
            # Skip if line_service not available
            if not self.line_service:
                logger.warning("LineService not available, skipping Submission AI debug info push")
                return

            import time

            # Parse arguments to get query
            arguments = json.loads(arguments_str)
            query = arguments.get("query", "")

            # Build debug message
            debug_msg = "ğŸ” Submission AI å›è¦†ï¼š\n"
            debug_msg += "â”€" * 30 + "\n"
            debug_msg += f"ğŸ“ æŸ¥è©¢ï¼š{query}\n"
            debug_msg += "\nğŸ’¬ Submission AI å›ç­”ï¼š\n"
            debug_msg += f"{result}\n"
            debug_msg += "â”€" * 30

            # Push message
            time.sleep(0.3)  # Small delay to ensure proper message order
            self.line_service.push_message(user_id, debug_msg)

            logger.info(f"Pushed Submission AI debug info to user {user_id}")

        except Exception as e:
            logger.error(f"Failed to push Submission AI debug info: {e}")
            # Don't raise - debug info failure shouldn't break the main flow


    
    

